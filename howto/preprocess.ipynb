{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import plotly.express as px\n",
    "from IPython.display import Audio\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an audio file  \n",
    "Loading and audio file from UrbanSound8K dataset, or provide a short `.wav` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sound\n",
    "audio_sample_path = Path('../data/audio/fold1/106905-8-0-1.wav')\n",
    "signal, sr = torchaudio.load(str(audio_sample_path))\n",
    "# reduce to one channel\n",
    "signal = signal.mean(axis=0)  \n",
    "# resample to 22050 Hz\n",
    "resampler = torchaudio.transforms.Resample(sr, 22050)\n",
    "signal, sr = resampler(signal), 22050\n",
    "#\n",
    "Audio(signal, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "With librosa, we use two functions to slighly modify the sample :  \n",
    "- Pitch shifting \n",
    "- Time streching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "pitch_shift = np.random.randint(-2, 3)  # shifting pitch from -2 to 2 semi tone\n",
    "time_stretch = np.random.random() * (1.2 - 0.9) + 0.9  # speed up if > 1, slow down if < 1\n",
    "print(pitch_shift, time_stretch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_augmented = torch.tensor(librosa.effects.time_stretch(librosa.effects.pitch_shift(signal.numpy(), sr=sr, n_steps=pitch_shift), rate=time_stretch))\n",
    "# Then the signal is cut or padded to get the same length between the original and the augmented signal\n",
    "delta_ln = len(signal) - len(signal_augmented)\n",
    "if delta_ln < 0:\n",
    "    signal_augmented = signal_augmented[:len(signal)]\n",
    "else:\n",
    "    signal_augmented = torch.hstack([signal_augmented, torch.zeros(delta_ln)])\n",
    "#\n",
    "Audio(signal_augmented, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import MelSpectrogram\n",
    "N_FFT, HOP_LENGTH, N_MELS = 1024, 256, 128\n",
    "transform = MelSpectrogram(\n",
    "    sample_rate=sr,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_mels=N_MELS, \n",
    "    center=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spec = transform(signal)\n",
    "mel_spec_augmented = transform(signal_augmented)\n",
    "# normalize Mel Spectrogram\n",
    "mel_spec /= torch.max(mel_spec)\n",
    "mel_spec_augmented /=torch.max(mel_spec_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visiualize with plotly\n",
    "mel_specs = torch.dstack([mel_spec, mel_spec_augmented])\n",
    "fig = px.imshow(mel_specs, animation_frame=2, aspect=\"auto\")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "927bfdf98abe9f7847163d625b518027ffb9f82019626fe65746d2bd5bc05af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
